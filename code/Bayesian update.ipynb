{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "#first some imports\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)  # double precision for numerical stability\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Infer(sampling_func, num_samples=50):\n",
    "    \"\"\"\n",
    "    Estimate a distribution by importance sampling\n",
    "    \"\"\"\n",
    "    return(pyro.infer.EmpiricalMarginal(\n",
    "        pyro.infer.Importance(\n",
    "            sampling_func, num_samples=num_samples).run()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Game environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# colors\n",
    "GREEN = 0\n",
    "YELLOW = 1\n",
    "WHITE = 2\n",
    "BLUE = 3\n",
    "RED = 4\n",
    "ALL_COLORS = [GREEN, YELLOW, WHITE, BLUE, RED]\n",
    "\n",
    "# ranks\n",
    "ONE = 0\n",
    "TWO = 1\n",
    "THREE = 2\n",
    "FOUR = 3\n",
    "FIVE = 4\n",
    "ALL_RANKS = [ONE, TWO, THREE, FOUR, FIVE]\n",
    "\n",
    "# actions\n",
    "HINT_COLOR = 0\n",
    "HINT_NUMBER = 1\n",
    "PLAY = 2\n",
    "DISCARD = 3\n",
    "\n",
    "# misc.\n",
    "HINT_MAX = 7\n",
    "LIFE_MAX = 3\n",
    "COUNT = [3,2,2,2,1]\n",
    "\n",
    "def init_context(num_player, num_card):\n",
    "    return {'life_tokens': LIFE_MAX, # game ends if ==0\n",
    "            'information_tokens': HINT_MAX,\n",
    "            # top of played cards 0-index based (-1 means no card for the color played)\n",
    "            'fireworks': {GREEN: -1, YELLOW: -1, WHITE: -1, BLUE: -1, RED: -1},  \n",
    "            # trashed/fasely played in forms of e.g. {'color':BLUE, 'rank':ONE}\n",
    "            'discard_pile': [],  \n",
    "            # specific realisation allowed by knowledge, used for update step\n",
    "            'hand': [[{'color':None, 'rank':None} for c in range(num_card)] for p in range(num_player)],\n",
    "            # num.instance for [player][card][color][rank]\n",
    "            'knowledge': [[[COUNT for col in ALL_COLORS]\n",
    "                           for card in range(num_card)] for plyr in range(num_player)],\n",
    "            # possible actions: HINT_COLOR, HINT_NUMBER, PLAY, DISCARD\n",
    "            'last_action': {'type':None, 'pnr':None, 'cnr':None, 'color':None, 'rank':None} \n",
    "           }\n",
    "\n",
    "\n",
    "def CardPlayable(card, fireworks):\n",
    "    # rank should be one high up than the current highest to be played\n",
    "    if fireworks[card['color']] +1 == card['rank']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Card is not needed anymore in the future\n",
    "def CardUseless(card, fireworks):\n",
    "    if fireworks[card['color']] > int(card['rank']):\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def remaining_copies(card, discard_pile):\n",
    "    if card['rank'] == ONE:  # rank one\n",
    "        total_copies = 3\n",
    "    elif card['rank'] == FIVE:  # rank five\n",
    "        total_copies = 1\n",
    "    else:\n",
    "        total_copies = 2\n",
    "    \n",
    "    # count how many of the sort given by `card` is discarded\n",
    "    count = 0\n",
    "    for discarded in discard_pile:\n",
    "        col, rank = discarded['color'], discarded['rank']\n",
    "        if (col == card['color']) and (rank == card['rank']):\n",
    "            count += 1\n",
    "\n",
    "    return total_copies - count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate usuage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CardPlayable({'color':BLUE, 'rank':ONE}, \n",
    "             {GREEN: -1, YELLOW: -1, WHITE: -1, BLUE: 0, RED: -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# discard piles\n",
    "dp = [{'color':BLUE, 'rank':ONE}, {'color':BLUE, 'rank':TWO}, {'color':WHITE, 'rank':ONE}]\n",
    "\n",
    "remaining_copies({'color':BLUE, 'rank':TWO}, dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'life_tokens': 3,\n",
       " 'information_tokens': 7,\n",
       " 'fireworks': {0: -1, 1: -1, 2: -1, 3: -1, 4: -1},\n",
       " 'discard_pile': [],\n",
       " 'hand': [[{'color': None, 'rank': None}, {'color': None, 'rank': None}],\n",
       "  [{'color': None, 'rank': None}, {'color': None, 'rank': None}],\n",
       "  [{'color': None, 'rank': None}, {'color': None, 'rank': None}]],\n",
       " 'knowledge': [[[[3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1]],\n",
       "   [[3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1]]],\n",
       "  [[[3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1]],\n",
       "   [[3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1]]],\n",
       "  [[[3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1]],\n",
       "   [[3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1],\n",
       "    [3, 2, 2, 2, 1]]]],\n",
       " 'last_action': {'type': None,\n",
       "  'pnr': None,\n",
       "  'cnr': None,\n",
       "  'color': None,\n",
       "  'rank': None}}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_player = 3 \n",
    "num_card = 2\n",
    "context = init_context(num_player, num_card)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_game(context, last_action):\n",
    "    '''\n",
    "    Adapt context accordingly based on last_action\n",
    "    '''\n",
    "    nc = copy.deepcopy(context)\n",
    "    # update last_action\n",
    "    nc['last_action'] = copy.deepcopy(last_action)\n",
    "\n",
    "    # 1) PLAY\n",
    "    if last_action['type'] == 'PLAY':\n",
    "        # i) update other stuff (hint token, error token, discard piles, fireworks)\n",
    "        card = {'color':last_action['color'],\n",
    "                         'rank':last_action['rank']}\n",
    "        # if played successfully\n",
    "        if CardPlayable(card, context['fireworks']):\n",
    "            # hint token\n",
    "            if (last_action['rank']  == FIVE) and ( # +1 hint for completing the deck\n",
    "                nc['information_tokens'] < HINT_MAX): # if hint token isn't full\n",
    "                nc['information_tokens'] += 1\n",
    "            # fireworks\n",
    "            nc['fireworks'][last_action['color']] = last_action['rank']\n",
    "        # wrong playing\n",
    "        else:\n",
    "            # error token\n",
    "            nc['life_tokens'] -= 1\n",
    "            # discard piles\n",
    "            nc['discard_pile'].append(card)\n",
    "        \n",
    "        # ii) update knowledge\n",
    "        # for a player that played the card, any cards newer than played card shift down by 1\n",
    "        for i in range(last_action['cnr'], num_card-1):\n",
    "            # knowledge[player][card]\n",
    "            nc['knowledge'][last_action['pnr']][i] = context['knowledge'][last_action['pnr']][i+1]\n",
    "        # draw a new card (highest card index, which is num_card-1)\n",
    "        nc['knowledge'][nc['last_action']['pnr']][num_card-1] = [[remaining_copies({'color':col, 'rank':rank}, nc['discard_pile'])\n",
    "                                                for rank in ALL_RANKS] for col in ALL_COLORS]\n",
    "                \n",
    "                       \n",
    "    \n",
    "#     elif nc['last_action']['type'] == 'DISCARD':\n",
    "# TODO: ask if Bianca could finish this function?\n",
    "    \n",
    "    return nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "demonstrate usuage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i) {'life_tokens': 2, 'information_tokens': 7, 'fireworks': {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, 'discard_pile': [{'color': 3, 'rank': 1}], 'hand': [[{'color': None, 'rank': None}, {'color': None, 'rank': None}], [{'color': None, 'rank': None}, {'color': None, 'rank': None}], [{'color': None, 'rank': None}, {'color': None, 'rank': None}]], 'knowledge': [[[[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1]], [[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1]]], [[[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1]], [[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 1, 2, 2, 1], [3, 2, 2, 2, 1]]], [[[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1]], [[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1]]]], 'last_action': {'type': 'PLAY', 'pnr': 1, 'cnr': 0, 'color': 3, 'rank': 1}}\n",
      "ii) {'life_tokens': 2, 'information_tokens': 7, 'fireworks': {0: -1, 1: -1, 2: -1, 3: 0, 4: -1}, 'discard_pile': [{'color': 3, 'rank': 1}], 'hand': [[{'color': None, 'rank': None}, {'color': None, 'rank': None}], [{'color': None, 'rank': None}, {'color': None, 'rank': None}], [{'color': None, 'rank': None}, {'color': None, 'rank': None}]], 'knowledge': [[[[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1]], [[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1]]], [[[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 1, 2, 2, 1], [3, 2, 2, 2, 1]], [[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 1, 2, 2, 1], [3, 2, 2, 2, 1]]], [[[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1]], [[3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1], [3, 2, 2, 2, 1]]]], 'last_action': {'type': 'PLAY', 'pnr': 1, 'cnr': 0, 'color': 3, 'rank': 0}}\n"
     ]
    }
   ],
   "source": [
    "# falsely play blue 2\n",
    "context = copy.deepcopy(update_game(context, {'type':'PLAY', 'pnr':1, 'cnr':0, 'color':BLUE, 'rank':TWO}) )\n",
    "print('i)', context)\n",
    "context = copy.deepcopy(update_game(context, {'type':'PLAY', 'pnr':1, 'cnr':0, 'color':BLUE, 'rank':ONE}) )\n",
    "print('ii)', context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Marginalise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxilary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_realisation_indicies(num_player, num_card):\n",
    "    '''\n",
    "    Aux. function emul_marg(). \n",
    "    Returns indicies which has a dimension of num_player x num_card x 4. For each card of each player,\n",
    "    a vector of with length 4 is decided. The first two elements represent player and card indicies.\n",
    "    The following elements are sampled randomly which choose color and rank of the card respectively.\n",
    "    '''\n",
    "    mya = [[[pi,i] for i in range(num_card)]  for pi in range(num_player)]  # (num_player, num_card, 2)\n",
    "    realisation_i = np.random.randint(low=0, high=5, size=(num_player,num_card,2)) \n",
    "    return np.concatenate((mya, realisation_i), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### emul_marg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emul_marg(last_action, context, player_index, card_index):\n",
    "    '''\n",
    "    :param last_action: dict, information about type, player, card, color and rank of the last action\n",
    "    :param context: dict, general game situations and knowledge structure\n",
    "    :param player_index: int, 0-based index of player for which the intention should be updated\n",
    "    :param card_index: int, 0-based index of card \" \"\n",
    "    :returns : (,3) np.array, which is a simplex with probability for each sort of intention (PLAY, DISCARD, KEEP)\n",
    "    '''\n",
    "    \n",
    "    # Initialize\n",
    "    threshold = 20  # num. of realisations to iterate over. Ideally, sum over all realisations\n",
    "    # plyr(4)*card(4)*col(5)*rank(5) = 400 realisations\n",
    "    # TODO: maybe also implement time limit (Minseok) \n",
    "    samples = np.zeros((threshold, 3)) # each sample is a simplex with 3 categories (play, discard, keep)\n",
    "    \n",
    "    # Restrict possible realisations by emulating last action\n",
    "    my_knowledge = copy.deepcopy(update_game(action, context)['knowledge'])\n",
    "    \n",
    "    for sample_i in range(threshold):\n",
    "        # Use rejection sampling\n",
    "        while True:\n",
    "            # single instance of a complete realisation indicies (choose reali. for each card for each plyr)          \n",
    "            c_r_i = get_realisation_indicies(num_player, num_card)\n",
    "            # numerator: num. instance for a chosen realisation of a chosen card\n",
    "            # denominator: total num. possible instance for a chosen card\n",
    "            probs = [my_knowledge[c_r_i[pi,i,0]][c_r_i[pi,i,1]][c_r_i[pi,i,2]][c_r_i[pi,i,3]] /\n",
    "                          np.sum(my_knowledge[pi][i])\n",
    "                              for pi in range(num_player) for i in range(num_card)]\n",
    "            \n",
    "            # Reject samples that cannot happen\n",
    "            if not np.all(probs > 0):  # rejected\n",
    "                pass # so go back into infinite loop again\n",
    "            else:  # accept since no cards with p=0\n",
    "                # Proceed with choosing r\n",
    "                realisation = copy.deepcopy(estimated_board)\n",
    "                realisation['hand'] = [  # fix color and rank for each card for each plyr\n",
    "                [{'color': ci[pi,i], 'rank': ri[pi,i]} for pi in range(num_player)] for i in range(num_card)]  \n",
    "                \n",
    "                # Collect P(r|a,c) * P(i|r) for single r given \n",
    "                samples[sample_i] = np.exp(np.sum(np.log(probs))) * pragmatic_listener( # P(r|a,c)\n",
    "                    realisation, card_index, player_index)  # P(i|r)\n",
    "                break # break the infinite loop\n",
    "    \n",
    "    # Approximate density when enough samples are there\n",
    "    grid = GridSearchCV(KernelDensity(), # use CV to choose best bandwidth for smoothing\n",
    "                        {'bandwidth': np.logspace(-1, 1, 20)})  \n",
    "    grid.fit(samples)\n",
    "    kde = grid.best_estimator_\n",
    "    \n",
    "    # TODO: compute median (50% quantile) A bit tricky since we have a categorical dist.\n",
    "#     return kde.score_samples()\n",
    "\n",
    "\n",
    "# TODO: instead of rejection sampling, consider MCMC. This also solves the problem of mean estimate automatically.\n",
    "# https://docs.pymc.io/api/inference.html?highlight=sample_ppc\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "#         # Collect samples which approximate P(r|a,c)  \n",
    "#         while True: # use rejection sampling (samples is valid only if p>0)\n",
    "#             log_prob = np.zeros(num_player, num_card)  # collect log_prob for each card\n",
    "#             # Sample indicies for choosing a realisation (r)\n",
    "#             ci, ri = np.random.randint( # color, rank indicies for every hand of every plyr\n",
    "#                 low=0, high=5, size=(2, num_player, num_card)) \n",
    "#             # Assuming independence, sum over log_prob of all cards\n",
    "#             for pi in range(num_player): \n",
    "#                 for i in range(num_card):\n",
    "#                     numer = my_knowledge[pi][i][ci[pi,i]][ri[pi,i]] # num. instance of the specific reali.\n",
    "#                     denom = np.sum(my_knowledge[pi][i]) # total num. instance for the card\n",
    "#                     log_prob[pi][i] = np.log(numer/denom)\n",
    "#             if np.all(np.exp(log_prob) != 0): # sample is valid only if no summand has 0 prob\n",
    "#                 break  # TODO: prolly lots of samples get rejected here, more efficient sampling needed\n",
    "\n",
    "#         # Choose a realisation (r)\n",
    "#         realisation = copy.deepcopy(estimated_board)\n",
    "#         realisation['hand'] = [  # fix color and rank for each card\n",
    "#             [{'color': c_r_i[pi,i,2], 'rank': c_r_i[pi,i,3]} \n",
    "#              for pi in range(num_player)] for i in range(num_card)]          \n",
    "#         print('realisation', realisation)\n",
    "\n",
    "#         # Compute a sample of P(i|a,c) = P\n",
    "#         samples.append(np.exp(log_prob) * \n",
    "#                        pragmatic_listener(realisation, card_index, player_index))  # vector of dim 3 gets appended\n",
    "\n",
    "#         # return mean_posterior(approx_density(samples))  # TODO: mean of density of samples\n",
    "#         # https://docs.pymc.io/api/inference.html?highlight=sample_ppc\n",
    "#     # 7. compute mean_posterior of samples \n",
    "#     grid = GridSearchCV(KernelDensity(), {'bandwidth': np.logspace(-1, 1, 20)})  # use CV to choose best bandwidth\n",
    "#     grid.fit(samples)\n",
    "#     kde = grid.best_estimator_\n",
    "    \n",
    "#     return np.max(KernelDensity(kernel='gaussian', bandwidth=0.1).fit(samples))\n",
    "#     # use MLE for the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snippet demonstrating how density estimation could be done using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [[0.1, 0.2, 0.7], [0.11, 0.19, 0.7], [0.15, 0.2, 0.65], [0.14, 0.21, 0.65], [0.12, 0.2, 0.68]] # some fake samples, all simplex\n",
    "grid = GridSearchCV(KernelDensity(), {'bandwidth': np.logspace(-1, 1, 20)})  # use CV to choose best bandwidth\n",
    "grid.fit(samples)\n",
    "kde = grid.best_estimator_\n",
    "kde.score_samples([[0.05,0.25,0.7]])  # log_prob of a given sample\n",
    "# one could in principle do grid search to find MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pragmatic listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_prior():\n",
    "    # TODO: think about a proper prior, uniform at the moment\n",
    "    sample = pyro.sample(\"utt\", dist.Categorical(probs=torch.ones(3) / 3))\n",
    "    if sample == 0:\n",
    "        return 'play'\n",
    "    elif sample ==1:\n",
    "        return 'keep'\n",
    "    else:\n",
    "        return 'discard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pragmatic_listener(realisation, card_index, player_index):\n",
    "    def sample_pl(context, card_index, player_index):\n",
    "        intention = int_prior() # P(i)\n",
    "        pyro.sample(\"pragmatic_speaker\", # P(r|i)\n",
    "                    pragmatic_speaker(intention, realisation, card_index, player_index), obs=action) \n",
    "        return intention\n",
    "    return Infer(sample_pl(context,card_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pragmatic speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pragmatic_speaker(intention, realisation, player_index, card_index):\n",
    "    alpha = 1 # TODO: fit(adjust) rationality parameter according to behaviour of coplyr\n",
    "    \n",
    "    # compute numerator\n",
    "    numerator = utility(intention, realisation, card_index, player_index)\n",
    "    numerator = np.exp(alpha * numerator)\n",
    "    \n",
    "    # compute denominator\n",
    "    denominator = 0\n",
    "    for r in possible_realisations:  # TODO: possible_realisations should come from emul_marg\n",
    "        summand = utility(intention, r, card_index, player_index)\n",
    "        summand = np.exp(alpha * summand)\n",
    "        denominator += summand\n",
    "        \n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'possible_realisations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-72179404ebc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m pragmatic_speaker(intention='play',\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0mrealisation\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mreali\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mplayer_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mcard_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-185-0bedf85e8a18>\u001b[0m in \u001b[0;36mpragmatic_speaker\u001b[0;34m(intention, realisation, player_index, card_index)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# compute denominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_realisations\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: possible_realisations should come from emul_marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0msummand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcard_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msummand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msummand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'possible_realisations' is not defined"
     ]
    }
   ],
   "source": [
    "pragmatic_speaker(intention='play',\n",
    "                  realisation= reali,\n",
    "                  player_index=0,\n",
    "                  card_index=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Utility function (hand-crafted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility as suggested by Saskia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility(intention, realisation, player_index, card_index):\n",
    "    '''\n",
    "    return a utility for a given card (decided by card_index, player_index) of a given realisation from various realisations\n",
    "    '''\n",
    "    score = 0\n",
    "    card = copy.deepcopy(realisation['hand'][player_index][card_index])  # select a card\n",
    "\n",
    "    if intention == 'play':\n",
    "        # in intention is play and card is playable, \n",
    "        # this results in one more card on the fireworks.\n",
    "        # reward this.\n",
    "        if CardPlayable(card, realisation['fireworks']):\n",
    "            score += 10\n",
    "\n",
    "        # if intention is play and card is not playable at the time\n",
    "        else:\n",
    "            # punish loosing a card from stack\n",
    "            score -= 1\n",
    "            # and punish getting a bomb depending on the number of bombs\n",
    "            if realisation['life_tokens'] == 3:\n",
    "                score -= 1\n",
    "            elif realisation['life_tokens'] == 2:\n",
    "                score -= 3\n",
    "            elif realisation['life_tokens'] == 1: # game would end directly\n",
    "                score -= 25\n",
    "\n",
    "            # if card would still have been relevant in the future,\n",
    "            # punish loosing it depending on the remaining copies of this card in the deck\n",
    "            if not CardUseless(card, realisation['fireworks']):\n",
    "                if remaining_copies(card, realisation['discard_pile']) == 2:\n",
    "                    score -= 1\n",
    "                elif remaining_copies(card, realisation['discard_pile']) == 1:\n",
    "                    score -= 2\n",
    "                elif remaining_copies(card, realisation['discard_pile']) == 0:\n",
    "                    score -= 5\n",
    "\n",
    "\n",
    "    elif intention == 'discard':\n",
    "        # punish loosing a card from stack\n",
    "        score -= 1\n",
    "\n",
    "        # reward gaining a hint token:\n",
    "        score += 0.5\n",
    "\n",
    "        # punish discarding a playable card\n",
    "        if CardPlayable(card, realisation['fireworks']):\n",
    "            score -= 5\n",
    "\n",
    "        # if card is not playable right now but would have been relevant in the future, punish\n",
    "        # discarding it depending on the number of remaining copies in the game\n",
    "        elif not CardUseless(card, realisation['fireworks']):\n",
    "            if remaining_copies(card, realisation['discard_pile']) == 2:\n",
    "                score -= 1\n",
    "            elif remaining_copies(card, realisation['discard_pile']) == 1:\n",
    "                score -= 2\n",
    "            elif remaining_copies(card, realisation['discard_pile']) == 0:\n",
    "                score -= 5\n",
    "\n",
    "        # do we want to reward this additionally? I think rewarding gaining a hint token should be\n",
    "        # enough, so nothing happens here\n",
    "        elif CardUseless(card, realisation['fireworks']):\n",
    "            pass\n",
    "\n",
    "    elif intention == 'keep':\n",
    "        # keeping a playable card is punished, because it does not help the game\n",
    "        if CardPlayable(card, realisation['fireworks']):\n",
    "            score -= 2\n",
    "\n",
    "        # if card is not playable right now but is relevant in the future of the game reward keeping\n",
    "        # this card depending on the remaining copies in the game\n",
    "        elif not CardUseless(card, realisation['fireworks']):\n",
    "            if remaining_copies(card, realisation['discard_pile']) == 2:\n",
    "                score += 1\n",
    "            elif remaining_copies(card, realisation['discard_pile']) == 1:\n",
    "                score += 2\n",
    "            elif remaining_copies(card, realisation['discard_pile']) == 0:\n",
    "                score += 5\n",
    "\n",
    "        # punish keeping a useless card\n",
    "        elif CardUseless(card, realisation['fireworks']):\n",
    "            score -= 1\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowledge_structure = copy.deepcopy(context['knowledge'])\n",
    "# knowledge_structure[0] = [  # of player 0\n",
    "#     [[2,0,2,2,1], [0,0,2,2,1], [2,0,2,2,1], [2,0,2,2,1], [2,0,2,2,1]], # card 0\n",
    "#     [[0,0,2,2,0], [2,0,2,1,1], [2,0,0,0,0], [2,0,2,2,1], [2,0,0,0,0]]] # card\n",
    "# # unrealistic but suppose every plyr have same card possibilities for simplicity\n",
    "# knowledge_structure[1] = copy.deepcopy(knowledge_structure[0])\n",
    "# knowledge_structure[2] = copy.deepcopy(knowledge_structure[0])\n",
    "# # plyr 1 played their first card, which was Blue 3\n",
    "# last_action = {'type':'PLAY', 'pnr':1, 'cnr':0, 'col':'B', 'num':3} \n",
    "\n",
    "\n",
    "reali = {'life_tokens': 3, # game ends if ==0\n",
    "         'information_tokens': 7, # hint token\n",
    "         'fireworks': {RED: THREE, YELLOW: TWO, GREEN: FOUR, WHITE: -1, BLUE: -1},\n",
    "         'discard_pile': [{'color':BLUE,'rank':ONE}, {'color':BLUE,'rank':ONE}, {'color':BLUE,'rank':THREE}],\n",
    "         'hand': [\n",
    "             [{'color':BLUE,'rank':TWO}, {'color':RED,'rank':ONE}],  # 3 plyr x 2 card\n",
    "             [{'color':BLUE,'rank':FOUR}, {'color':YELLOW,'rank':ONE}],\n",
    "             [{'color':BLUE,'rank':ONE}, {'color':WHITE,'rank':THREE}]],\n",
    "         'knowledge_structure': None  # doesn't matter for utility\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'life_tokens': 3,\n",
       " 'information_tokens': 7,\n",
       " 'fireworks': {4: 2, 1: 1, 0: 3, 2: -1, 3: -1},\n",
       " 'discard_pile': [{'color': 3, 'rank': 0},\n",
       "  {'color': 3, 'rank': 0},\n",
       "  {'color': 3, 'rank': 2}],\n",
       " 'hand': [[{'color': 3, 'rank': 1}, {'color': 4, 'rank': 0}],\n",
       "  [{'color': 3, 'rank': 3}, {'color': 1, 'rank': 0}],\n",
       "  [{'color': 3, 'rank': 0}, {'color': 2, 'rank': 2}]],\n",
       " 'knowledge_structure': None}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility('play', reali, 2, 0)  # BLUE ONE in this example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
